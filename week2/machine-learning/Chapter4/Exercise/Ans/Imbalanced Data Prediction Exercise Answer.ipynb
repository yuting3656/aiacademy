{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pylab import rcParams\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 9, 6\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make 3-class dataset for classification\n",
    "center1 = [[0, 0]]\n",
    "X1, y1 = make_blobs(n_samples=800, centers=center1, random_state=42)\n",
    "center2 = [[0, 0],[1, 1]]\n",
    "X2, y2 = make_blobs(n_samples=200, centers=center2, random_state=42, cluster_std=0.3)\n",
    "X = np.vstack((X1, X2))\n",
    "y = np.hstack((y1, y2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 在圖上紅色點表示為壞人(1)，藍色點是好人(0)\n",
    "* 今天身為一位警察該如何透過兩個 feature 從好人中去抓出壞人呢？\n",
    "* 這邊產生的資料只有 20% 是壞人，80% 是好人"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color = \"br\"\n",
    "color = [color[y[i]] for i in range(len(y))]\n",
    "plt.scatter(X[:,0],X[:,1],c=color,alpha=.5)\n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict with Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(X)\n",
    "print('Accuracy:%.2f'%model.score(X, y))\n",
    "color = \"br\"\n",
    "label = ['Good Sample', 'Bad Sample']\n",
    "#color = [color[prediction[i]] for i in range(len(y))]\n",
    "#label = [label[prediction[i]] for i in range(len(y))]\n",
    "for i in range(2):\n",
    "    plt.scatter(X[y==i][:,0],X[y==i][:,1],c=color[i],label=label[i],alpha=.5)\n",
    "plt.legend()    \n",
    "plt.xlabel('Feature1')\n",
    "plt.ylabel('Feature2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 利用預測機率代替預測結果\n",
    "* ### 在分類問題中，不管 logistic regression 還是 svm 都是在求解 maxmum likelyhood，因此最後算出來的邊界都是一個軟性邊界（機率分佈）  \n",
    "### 例如在上面的 logistic regression 模型預測機率如下 model.predict_proba(X) 所示  \n",
    "### 第一欄代表被預測為 0（好人）的機率，第二欄代表被預測為 1（壞人）的機率。\n",
    "### 在一般 model.predict() 給出的預測值是直接比較第一欄和第二欄的大小決定的，好人的機率大於壞人的機率，就會預測這筆資料為 0。\n",
    "### 但是在 imbalanced data 的情況下，我們會去調整 threshold 以達到目的。  \n",
    "### 假設我們在這個 case 中想要抓出大部分的壞人，那也許我們可以設定被預測為 1 的機率大於 20% 那我們就認定他是壞人，如此的話就可以抓出大部分的壞人，那 20% 就是我們所設定的 threshold。\n",
    "### 之前有提到一般以 F1_score 來權衡 precision 和 recall，因此在這樣的 case 下我們會去調整 threshold 來求得最大的 F1_score。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_proba(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.predict_proba(X)[0], '--->', model.predict(X)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定義 function \n",
    "# 比較各個不同 threshold 所形成的分類圖。\n",
    "* ### 這邊主要是要將分類問圖形化給大家看，如果看不懂的話只要知道fucntion的輸入為\n",
    "    * ### 1. model_type: 可選擇 Logistic 或 SVC\n",
    "    * ### 2. plot_dict: key 值為設定的 threshold，value 代表的是 subplot 的 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auc(model_type, plot_dict):\n",
    "    model_dict = {\n",
    "        'Logistic':LogisticRegression(),\n",
    "        'SVC':SVC(kernel='rbf', probability= True)\n",
    "    }\n",
    "\n",
    "    model = model_dict[model_type]\n",
    "    model.fit(X, y)\n",
    "    tpr_temp=[]\n",
    "    fpr_temp=[]\n",
    "    precision_temp=[]\n",
    "    recall_temp=[]\n",
    "    f1_score_temp=[]\n",
    "    for  threshold in plot_dict:\n",
    "        # 將預測機率大於 threshold 的分類為 1\n",
    "        pred = (model.predict_proba(X)[:,1] >= threshold).astype(int) \n",
    "        \n",
    "        # 先算出 confusion matrix 再算出其他評估值\n",
    "        cm = confusion_matrix(y, pred)\n",
    "        tpr = cm[1][1]/cm.sum(axis=1)[1]\n",
    "        fpr = cm[0][1]/cm.sum(axis=1)[0]\n",
    "        pre = cm[1][1]/cm.sum(axis=0)[1] # precision\n",
    "        re = cm[1][1]/cm.sum(axis=1)[1] # recall\n",
    "        f1 = 2*(pre*re)/(pre+re) # f1-score\n",
    "        \n",
    "        # 畫圖\n",
    "        color = \"br\"\n",
    "        color = [color[pred[j]] for j in range(len(pred))]\n",
    "        plt.subplot(plot_dict[threshold])\n",
    "        plt.tight_layout()\n",
    "        plt.scatter(X[:,0],X[:,1],c=color,alpha=.5)\n",
    "        plt.title('threshold:%.2f'%threshold+'\\n'+'accuracy:%.2f'%accuracy_score(y, pred)\n",
    "                  +'\\n'+'precision:%.2f'%pre+'\\n'+'recall:%.2f'%re+'\\n'+'f1-score:%.2f'%f1)\n",
    "        \n",
    "        \n",
    "        # 將各種評估值存取成 list 回傳\n",
    "        tpr_temp.append(tpr)\n",
    "        fpr_temp.append(fpr)\n",
    "        precision_temp.append(pre)\n",
    "        recall_temp.append(re)\n",
    "        f1_score_temp.append('nan' if f1!=f1 else round(f1,3))\n",
    "    \n",
    "    return f1_score_temp, tpr_temp, fpr_temp, precision_temp, recall_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with varied threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10.5,7))\n",
    "\n",
    "plot_dict = {0.85:241,0.8:242,0.6:243,0.5:244,0.4:245,0.3:246,0.2:247,0.1:248} \n",
    "# 自訂的 function 會回傳不同 threshold 的 f1_score, tpr, fpr, precision 和 recall\n",
    "f1_0, tpr0, fpr0, precision0, recall0 = auc('Logistic', plot_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Precision & Recall & F1_Score\n",
    "* 圖形化 Precsion Recall curve，並在個點旁邊標出對應的 f1_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(recall0 ,precision0, s=100)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve')\n",
    "# Show F1 Score on each point\n",
    "for i, txt in enumerate(f1_0):\n",
    "    plt.annotate(txt, (recall0[i]-0.05,precision0[i]+0.015), fontsize=14)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM with Varied threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10.5,7))\n",
    "plot_dict = {0.1:241,0.2:242,0.3:243,0.4:244,0.5:245,0.6:246,0.8:247,1:248}\n",
    "f1_1, tpr1, fpr1, precision1, recall1 = auc('SVC', plot_dict )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Performance between Logistic Regression & SVM\n",
    "* 比較 logistic regression 和 SVM 的 auc score，大家應該可以清楚地看出來哪個模型在這個問題中表現比較好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(recall0, precision0, '.', label = 'Logistic Regression', markersize=20)\n",
    "plt.plot(recall1, precision1, '.', label = 'SVM', markersize=20)\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.plot(fpr0, tpr0, '.', label = 'Logistic Regression', markersize=20)\n",
    "plt.plot(fpr1, tpr1, '.', label = 'SVM', markersize=20)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend()\n",
    "plt.title('ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 有興趣的同學可以查詢 ROC 曲線\n",
    "* roc curve 底下的面積 AUC 是很常見的一種 evaluation 方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
